{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b90df634-9fae-43e2-91c6-4c86a15d0ffb",
   "metadata": {},
   "source": [
    "# Meta Analysis Notebook\n",
    "\n",
    "## Steps\n",
    "\n",
    "**Pre-processing**\n",
    "\n",
    "- Set up directories for meta-analysis\n",
    "- Concatenate and compress GWAS results\n",
    "\n",
    "**Input Files**\n",
    "\n",
    "`input/analysis.json` - this file defines the directory with the results (summary statistics) from the GWAS pipeline for a given outcome. The structure of the file is as follows\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"Study\": {\n",
    "    \"cohorts\": [     // define the study arms in the analysis\n",
    "      \"PD\",\n",
    "      \"HC\"\n",
    "    ],\n",
    "    \"results\": [\n",
    "      {\n",
    "        \"path\": \"Study_2022-03-07T1903831\",\n",
    "        \"outcome\": \"outcome_1\",\n",
    "        \"mode\": \"lt\"\n",
    "      },\n",
    "      {\n",
    "        \"path\": \"Study_2022-03-07T1903846\",\n",
    "        \"outcome\": \"outcome_1\",\n",
    "        \"mode\": \"cs\"\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "1. Calculate lambdas from p-values\n",
    "2. Run meta-analysis with METAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4eee978-eec2-4a02-8177-cbba8634eba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2308f0f-200f-4768-b250-ed2dab9df438",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a571512a-6e20-4136-af22-58debaee46a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "files['base'] = Path('')\n",
    "files['base/results'] = files['base'] / 'results'\n",
    "files['base/METAL'] = files['base'] / 'METAL'\n",
    "\n",
    "files['jobs'] = files['base'] / 'jobs'\n",
    "files['METAL/raw_summary_stats'] = files['base/METAL'] / 'raw_summary_stats'\n",
    "files['METAL/lt'] = files['base/METAL'] / 'meta_analysis/lt'\n",
    "files['METAL/cs'] = files['base/METAL'] / 'meta_analysis/cs'\n",
    "\n",
    "\n",
    "files['lambda.csv'] = files['METAL/raw_summary_stats'] / 'lambda.csv'\n",
    "files['analysis.json'] = files['base'] / 'input/analysis.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cbaf2e3-e930-42ee-af68-1db738ed0198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create meta-analysis directory\n",
    "if not os.path.exists( files['METAL/raw_summary_stats'] / 'lt' ):\n",
    "  os.makedirs( files['METAL/raw_summary_stats'] / 'lt' )\n",
    "if not os.path.exists( files['METAL/raw_summary_stats'] / 'cs' ):\n",
    "  os.makedirs( files['METAL/raw_summary_stats'] / 'cs')\n",
    "  \n",
    "if not os.path.exists( files['base/METAL'] / 'meta_analysis/lt' ):\n",
    "  os.makedirs( files['METAL/lt'] )\n",
    "if not os.path.exists( files['base/METAL'] / 'meta_analysis/cs' ):\n",
    "  os.makedirs( files['METAL/cs'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce32a961-a7b7-45a7-a3d8-403f9f2dfbee",
   "metadata": {},
   "source": [
    "## Pre-Processing - concatenate results from GWAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a05e823c-5611-4485-9ad7-a3c5a9b21069",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(files['analysis.json'], 'r') as f:\n",
    "  outcomes = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1022995d-4039-4d02-9c43-1980b0e255cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmds = []\n",
    "\n",
    "## define lambda function to filter outcomes from analysis.json - use None for all\n",
    "criteria = {\n",
    "  None: lambda x: True,\n",
    "  'cs': lambda x: x['mode'] == 'cs'\n",
    "}\n",
    "\n",
    "\n",
    "for study in outcomes.keys():\n",
    "  sel_outcomes = filter( criteria['cs'], outcomes[study]['results'] )\n",
    "  sel_outcomes = list(sel_outcomes)\n",
    "  if len(sel_outcomes) < 1:\n",
    "    continue\n",
    "  \n",
    "  for cohort in outcomes[study]['cohorts']:\n",
    "    study = study.split('/')[0]\n",
    "    c = f'EUR_{study}-{cohort}'\n",
    "    for oc in sel_outcomes:\n",
    "      cmd = [\"/data/CARD/projects/longGWASnextflow/Scripts/preprocess.sh\"]\n",
    "      path = os.path.join(files['base/results'], oc['path'], c)\n",
    "      cmd.append(path)\n",
    "      cmd.append(\"| bgzip >\")\n",
    "\n",
    "      suffix = 'gallop.gz' if oc['mode'] == 'lt' else 'linear.gz'\n",
    "      out_path = files['METAL/raw_summary_stats'] / \\\n",
    "                 f\"{oc['mode']}/{c}_allchr.{oc['outcome']}.{suffix}\"\n",
    "\n",
    "      if os.path.exists(out_path):\n",
    "        continue\n",
    "      cmd.append(out_path)\n",
    "      cmds.append(' '.join( map(str, cmd)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "384871ff-7af3-49f0-bebf-7d023c487290",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cmds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m( os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(files[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjobs\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocess.outcomes.swarm\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mcmds\u001b[49m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cmds' is not defined"
     ]
    }
   ],
   "source": [
    "with open( os.path.join(files['jobs'], 'preprocess.outcomes.swarm'), 'w' ) as f:\n",
    "    f.write('\\n'.join(cmds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f262845-00ed-4def-af25-830111097499",
   "metadata": {},
   "source": [
    "#### Pre-process concatenate summary stats swarm job\n",
    "\n",
    "```bash\n",
    "swarm \\\n",
    "  --module python/3.8,samtools \\\n",
    "  -g 10 -p 2 \\\n",
    "  --time 01:15:00 \\\n",
    "  -f jobs/preprocess.outcomes.swarm \\\n",
    "  --partition quick,norm \\\n",
    "  --logdir logs/swarm_logs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c19ee1-44cb-4930-8382-01e02c74db6b",
   "metadata": {},
   "source": [
    "## Calculate Lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edb9ae0a-7cd6-48a6-afd5-51c65c996f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "972c3a22-d49e-4500-a3de-2616b5aac020",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 6/6 [00:00<00:00, 103138.62it/s]\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 291121.36it/s]\n"
     ]
    }
   ],
   "source": [
    "def calc_lambda(pvals):\n",
    "    return np.median(chi2.ppf(pvals, df=1)) / chi2.ppf(0.5, 1)\n",
    "\n",
    "cache_lambdas = None\n",
    "# grab cache values if exists\n",
    "if os.path.exists(files['lambda.csv']):\n",
    "  cache_lambdas = pd.read_csv(files['lambda.csv'], index_col=0)\n",
    "  \n",
    "tmp_dfs = []\n",
    "for m in ['cs', 'lt']:\n",
    "  tmp_files = os.listdir( files['METAL/raw_summary_stats'] / m )\n",
    "  tmp_files = list(filter(lambda x: x.endswith('.gallop.gz') or x.endswith('.linear.gz'), tmp_files))\n",
    "  for f in tqdm(tmp_files):\n",
    "    if cache_lambdas is not None and f'{m}/{f}' in cache_lambdas.index:\n",
    "      continue\n",
    "\n",
    "    fn = files['METAL/raw_summary_stats'] / f'{m}/{f}'\n",
    "    tmp_res = dict()\n",
    "    try:\n",
    "      tmp_df = pd.read_csv(fn, compression='gzip', sep='\\t', engine='c')\n",
    "    except pd.errors.EmptyDataError:\n",
    "      tmp_res[f'{m}/{f}'] = (np.NaN, np.NaN)\n",
    "      tmp_dfs.append(\n",
    "          pd.DataFrame.from_dict(tmp_res).T.rename(columns={0: 'Slope', 1: 'Intercept'}))\n",
    "\n",
    "    tmp_df = tmp_df[~(tmp_df.A1_FREQ < 0.05) & ~(tmp_df.A1_FREQ > 0.95)]\n",
    "    if m == 'lt':\n",
    "      tmp_res[f'{m}/{f}'] = (calc_lambda(tmp_df.Ps), calc_lambda(tmp_df.Pi))\n",
    "      tmp_dfs.append(\n",
    "          pd.DataFrame.from_dict(tmp_res).T.rename(columns={0: 'Slope', 1: 'Intercept'}))\n",
    "    else:\n",
    "      tmp_res[f'{m}/{f}'] = (np.NaN, calc_lambda(tmp_df.P))\n",
    "      tmp_dfs.append(\n",
    "          pd.DataFrame.from_dict(tmp_res).T.rename(columns={0: 'Slope', 1: 'Intercept'}))\n",
    "\n",
    "if len(tmp_dfs) > 0:\n",
    "  tmp_dfs = pd.concat(tmp_dfs)\n",
    "  if cache_lambdas is not None:\n",
    "    tmp_dfs = pd.concat([cache_lambdas, tmp_dfs])\n",
    "  tmp_dfs.to_csv(files['lambda.csv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49dc0b7-b052-47f7-bff5-7aed14f301b7",
   "metadata": {},
   "source": [
    "## Run METAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1313a53-2e9d-4878-a3bc-3bfd9c65091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_METAL_job(script, outcome, interest, indir, \n",
    "                      out, correction, cohorts, suffix=None):\n",
    "  cmd = [f'python {script}']\n",
    "  cmd.append(f'--outcome {outcome}')\n",
    "  cmd.append(f'--interest {effect}')\n",
    "  cmd.append(f'--indir {indir}')\n",
    "  cmd.append(f'--out {out}')\n",
    "  cmd.append(f'-c {correction}')\n",
    "  \n",
    "  if suffix is not None:\n",
    "    cmd.append(f'--suffix {suffix}')\n",
    "  \n",
    "  for c in cohorts:\n",
    "    cmd.append(f'-s {c}')\n",
    "  \n",
    "  return cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6d77b8d-f71e-4c8f-824e-9a07ad7b286b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will be mapped to concatenated summary stats\n",
    "cohorts = ['lt/EUR_PPMI-SWEDD',\n",
    "           'lt/EUR_PPMI-Genetic-Cohort-PD',\n",
    "           'lt/EUR_PPMI-Genetic-Cohort-Unaffected',\n",
    "           'lt/EUR_PPMI-Healthy-Control',\n",
    "           'lt/EUR_PPMI-PD',\n",
    "           'lt/EUR_PPMI-Prodromal',\n",
    "           'lt/EUR_ADNI-CN',\n",
    "           'lt/EUR_ADNI-MCI',\n",
    "           'lt/EUR_ADNI-Dementia',\n",
    "           'lt/EUR_PDBP-Healthy-Control',\n",
    "           'lt/EUR_PDBP-PD',\n",
    "           'cs/EUR_BioFIND-PD',\n",
    "           'cs/EUR_BioFIND-Healthy-Control']\n",
    "\n",
    "cohort_states = {\n",
    "  'HC': {\n",
    "    'lt/EUR_PPMI-Healthy-Control',\n",
    "    'lt/EUR_PPMI-Genetic-Cohort-Unaffected',\n",
    "    'lt/EUR_ADNI-CN',\n",
    "    'lt/EUR_PDBP-HC',\n",
    "    'cs/EUR_BioFIND-Healthy-Control'\n",
    "  },\n",
    "  'PD': {\n",
    "    'lt/EUR_PPMI-PD',\n",
    "    'lt/EUR_PDBP-PD',\n",
    "    'cs/EUR_BioFIND-PD'\n",
    "  },\n",
    "  'PD.all': {\n",
    "    'lt/EUR_PPMI-PD',\n",
    "    'lt/EUR_PPMI-Genetic-Cohort-PD',\n",
    "    'lt/EUR_PDBP-PD',\n",
    "    'cs/EUR_BioFIND-PD'\n",
    "  }\n",
    "}\n",
    "\n",
    "modes = {\n",
    "  'lt': ['Intercept', 'Slope'],\n",
    "  'cs': ['Intercept']\n",
    "}\n",
    "\n",
    "files['conductMETAL.py'] = '/data/CARD/projects/longGWASnextflow/Scripts/conductMETAL.py'\n",
    "\n",
    "\n",
    "filters = {\n",
    "  'lt': lambda x: x.startswith('lt/'),\n",
    "  'cs': lambda x: x.startswith('cs/'),\n",
    "  'HC': lambda x: x in cohort_states['HC'],\n",
    "  'PD.all': lambda x: x in cohort_states['PD.all'],\n",
    "  'PD': lambda x: x in cohort_states['PD'],\n",
    "  'PDBP': lambda x: x.split('_')[1].startswith('PDBP'),\n",
    "  'PPMI': lambda x: x.split('_')[1].startswith('PPMI'),\n",
    "  'BioFIND': lambda x: x.split('_')[1].startswith('BioFIND'),\n",
    "  'ADNI': lambda x: x.split('_')[1].startswith('ADNI'),\n",
    "  None: lambda x: True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85e30b01-4d0c-4dfd-83ec-5c4011e0deb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analysis General\n",
    "outcomes = ['log_CSF_Ab',\n",
    "            'log_CSF_pTau',\n",
    "            'log_CSF_tTau',]\n",
    "\n",
    "cmds = []\n",
    "m = 'lt'\n",
    "\n",
    "for effect in modes[m]:\n",
    "  for oc in outcomes:\n",
    "    cmd = conduct_METAL_job( files['conductMETAL.py'],\n",
    "                             oc, \n",
    "                             effect,\n",
    "                             files['base/METAL'],\n",
    "                             files[f'METAL/{m}'],\n",
    "                             files['lambda.csv'],\n",
    "                             filter(filters[None], cohorts) )\n",
    "  \n",
    "    cmds.append(' '.join(cmd))\n",
    "  \n",
    "fn = files['jobs'] / f'METAL.CSF_outcomes.{m}.swarm'\n",
    "\n",
    "with open( fn , 'w') as f:\n",
    "  f.write('\\n'.join(cmds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c8caa9d-c5c0-4d48-ac97-3173e43405fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Meta Analysis - By State\n",
    "outcomes = ['log_CSF_Ab',\n",
    "            'log_CSF_pTau',\n",
    "            'log_CSF_tTau',]\n",
    "\n",
    "cmds = []\n",
    "m = 'lt'\n",
    "\n",
    "for effect in modes[m]:\n",
    "  for oc in outcomes:\n",
    "    for sfx in ['HC', 'PD.all']:\n",
    "    #for sfx in ['PD']:\n",
    "      cmd = conduct_METAL_job( files['conductMETAL.py'],\n",
    "                               oc, \n",
    "                               effect,\n",
    "                               files['base/METAL'],\n",
    "                               files[f'METAL/{m}'],\n",
    "                               files['lambda.csv'],\n",
    "                               filter(filters[sfx], cohorts),\n",
    "                               sfx)\n",
    "  \n",
    "      cmds.append(' '.join(cmd))\n",
    "  \n",
    "fn = files['jobs'] / f'METAL.CSF_outcomes_states.{m}.swarm'\n",
    "\n",
    "with open( fn , 'w') as f:\n",
    "  f.write('\\n'.join(cmds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d10806e8-75ea-461d-9a22-7828a4ca9d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swarm \\\n",
      "  --module python/3.8,metal,samtools \\\n",
      "  -g 20 -p 2 \\\n",
      "  --time 02:30:00 \\\n",
      "  -f /data/CARD/projects/longGWASnextflow/BiomarkerGWAS-2/jobs/METAL.CSF_outcomes.lt.swarm \\\n",
      "  --partition quick,norm \\\n",
      "  --logdir logs/swarm_logs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "f\"\"\"swarm \\\\\n",
    "  --module python/3.8,metal,samtools \\\\\n",
    "  -g 20 -p 2 \\\\\n",
    "  --time 02:30:00 \\\\\n",
    "  -f {fn} \\\\\n",
    "  --partition quick,norm \\\\\n",
    "  --logdir logs/swarm_logs\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ccb8df-818d-4b1f-a30f-66e51f350384",
   "metadata": {},
   "source": [
    "### METAL for disease status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4465163-32e1-41f2-b1d3-b1b89801b90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "files['METAL/meta_analysis'] = files['base/METAL'] / 'meta_analysis'\n",
    "files['meta_analysis/lambda.csv'] = files['METAL/meta_analysis'] / 'lambda.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e619cee9-6e90-43fe-95cc-18e8e3c989f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 14/14 [04:55<00:00, 21.12s/it]\n",
      "100%|██████████████████████████████████████████████| 14/14 [05:24<00:00, 23.17s/it]\n",
      "100%|██████████████████████████████████████████████| 14/14 [04:57<00:00, 21.23s/it]\n"
     ]
    }
   ],
   "source": [
    "def calc_lambda(pvals):\n",
    "    return np.median(chi2.ppf(pvals, df=1)) / chi2.ppf(0.5, 1)\n",
    "\n",
    "cache_lambdas = None\n",
    "# grab cache values if exists\n",
    "if os.path.exists(files['meta_analysis/lambda.csv']):\n",
    "  cache_lambdas = pd.read_csv(files['meta_analysis/lambda.csv'], index_col=0)\n",
    "  \n",
    "tmp_dfs = []\n",
    "for m in ['cs', 'lt']:\n",
    "  for oc in os.listdir( files['METAL/meta_analysis'] / m ):\n",
    "    tmp_files = os.listdir( files['METAL/meta_analysis'] / m / oc )\n",
    "    tmp_files = list(filter(lambda x: x.endswith('.tbl'), tmp_files))\n",
    "    for f in tqdm(tmp_files):\n",
    "      if cache_lambdas is not None and f'{m}/{oc}/{f}' in cache_lambdas.index:\n",
    "        continue\n",
    "      key = f'{m}/{oc}/{f}'\n",
    "      fn = files['METAL/meta_analysis'] / key\n",
    "      tmp_res = dict()\n",
    "      try:\n",
    "        tmp_df = pd.read_csv(fn, sep='\\t', engine='c')\n",
    "      except pd.errors.EmptyDataError:\n",
    "        tmp_res[key] = (np.NaN,)\n",
    "        tmp_dfs.append(\n",
    "            pd.DataFrame.from_dict(tmp_res).T.rename(columns={0: 'Lambda'}))\n",
    "\n",
    "      tmp_df = tmp_df[~(tmp_df.Freq1 < 0.05) & ~(tmp_df.Freq1 > 0.95)]\n",
    "      tmp_res[key] = (calc_lambda(tmp_df['P-value']),)\n",
    "      tmp_dfs.append(\n",
    "          pd.DataFrame.from_dict(tmp_res).T.rename(columns={0: 'Lambda'}))\n",
    "\n",
    "tmp_dfs = pd.concat(tmp_dfs)\n",
    "if cache_lambdas is not None:\n",
    "  tmp_dfs = pd.concat([cache_lambdas, tmp_dfs])\n",
    "tmp_dfs.to_csv(files['meta_analysis/lambda.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c3d2f89-6594-4e89-afad-5f69768c7fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will be mapped to concatenated summary stats\n",
    "cohorts = {'lambda.csv': ['lt/EUR_ADNI-CN',\n",
    "                          'lt/EUR_ADNI-MCI',\n",
    "                          'lt/EUR_ADNI-Dementia'],\n",
    "           'meta_analysis/lambda.csv': []}\n",
    "\n",
    "for oc in ['log_CSF_Ab', 'log_CSF_pTau', 'log_CSF_tTau']:\n",
    "  for state in ['HC', 'PD.all']:\n",
    "    cohorts['meta_analysis/lambda.csv'].append(f'lt/{oc}/Pi_{state}1.tbl')\n",
    "    cohorts['meta_analysis/lambda.csv'].append(f'lt/{oc}/Ps_{state}1.tbl')\n",
    "\n",
    "modes = {\n",
    "  'lt': ['Intercept', 'Slope']\n",
    "}\n",
    "\n",
    "files['conductMETAL.py'] = '/data/CARD/projects/longGWASnextflow/Scripts/conductMETAL.py'\n",
    "\n",
    "\n",
    "filters = {\n",
    "  'lt': lambda x: x.startswith('lt/'),\n",
    "  'cs': lambda x: x.startswith('cs/'),\n",
    "  'HC': lambda x: x in cohort_states['HC'],\n",
    "  'PD.all': lambda x: x in cohort_states['PD.all'],\n",
    "  'PD': lambda x: x in cohort_states['PD'],\n",
    "  'PDBP': lambda x: x.split('_')[1].startswith('PDBP'),\n",
    "  'PPMI': lambda x: x.split('_')[1].startswith('PPMI'),\n",
    "  'BioFIND': lambda x: x.split('_')[1].startswith('BioFIND'),\n",
    "  'ADNI': lambda x: x.split('_')[1].startswith('ADNI'),\n",
    "  None: lambda x: True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d81a116-4dd5-4b7d-841e-fe743314fb9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lambda.csv': ['lt/EUR_ADNI-CN', 'lt/EUR_ADNI-MCI', 'lt/EUR_ADNI-Dementia'],\n",
       " 'meta_analysis/lambda.csv': ['lt/log_CSF_Ab/Pi_HC1.tbl',\n",
       "  'lt/log_CSF_Ab/Ps_HC1.tbl',\n",
       "  'lt/log_CSF_Ab/Pi_PD.all1.tbl',\n",
       "  'lt/log_CSF_Ab/Ps_PD.all1.tbl',\n",
       "  'lt/log_CSF_pTau/Pi_HC1.tbl',\n",
       "  'lt/log_CSF_pTau/Ps_HC1.tbl',\n",
       "  'lt/log_CSF_pTau/Pi_PD.all1.tbl',\n",
       "  'lt/log_CSF_pTau/Ps_PD.all1.tbl',\n",
       "  'lt/log_CSF_tTau/Pi_HC1.tbl',\n",
       "  'lt/log_CSF_tTau/Ps_HC1.tbl',\n",
       "  'lt/log_CSF_tTau/Pi_PD.all1.tbl',\n",
       "  'lt/log_CSF_tTau/Ps_PD.all1.tbl']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22956c22-bdbb-414a-8490-c8df33cbb67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(filters['PD.all'], cohorts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed4ab236-091d-45fe-a5b2-b64bbfffd29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Meta Analysis - By State\n",
    "outcomes = ['log_CSF_Ab',\n",
    "            'log_CSF_pTau',\n",
    "            'log_CSF_tTau',]\n",
    "\n",
    "cmds = []\n",
    "m = 'lt'\n",
    "\n",
    "for effect in modes[m]:\n",
    "  for oc in outcomes:\n",
    "    for sfx in ['HC', 'PD.all']:\n",
    "    #for sfx in ['PD']:\n",
    "      cmd = conduct_METAL_job( files['conductMETAL.py'],\n",
    "                               oc, \n",
    "                               effect,\n",
    "                               files['base/METAL'],\n",
    "                               files[f'METAL/{m}'],\n",
    "                               files['lambda.csv'],\n",
    "                               filter(filters[sfx], cohorts),\n",
    "                               sfx)\n",
    "  \n",
    "      cmds.append(' '.join(cmd))\n",
    "  \n",
    "fn = files['jobs'] / f'METAL.CSF_outcomes_{sfx}.{m}.swarm'\n",
    "\n",
    "with open( fn , 'w') as f:\n",
    "  f.write('\\n'.join(cmds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202c4103-cbff-4670-8c20-03d6093528de",
   "metadata": {},
   "outputs": [],
   "source": [
    "metal log_CSF_tTau/Ps_status.all.metal > log_CSF_tTau/Ps_status.all.metal.stdout"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python/3.8",
   "language": "python",
   "name": "py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
