{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef35e0a4-76df-4a10-b466-2b97c95c3524",
   "metadata": {},
   "source": [
    "# Running LocusCompare\n",
    "After obtaining a hit, you check the co-localization (with dose-dependent signal strength) between the GWAS results and eQTLs. Use the LocusCompare.    \n",
    "* [Abundant associations with gene expression complicate GWAS follow-up, Nature Genetics](https://www.nature.com/articles/s41588-019-0404-0) Boxiang Liu, Michael J. Gloudemans, Abhiram S. Rao, Erik Ingelsson & Stephen B. Montgomery (2019) \n",
    "\n",
    "The R versin of the software readme is [here](https://github.com/boxiangliu/locuscomparer)\n",
    "\n",
    "# Input file\n",
    "For LocusCompare we only need:\n",
    "\n",
    "    rsid\tpval    \n",
    "    rs62156064\t0.564395    \n",
    "    rs7562234\t0.399642    \n",
    "    rs11677377\t0.34308    \n",
    "    rs35076156\t0.625237\n",
    "\n",
    "Basic pipeline\n",
    "\n",
    "1. Decide the slicing range\n",
    "2. Slice the relevant locus for two summary stats\n",
    "3. Format the data\n",
    "4. Run the analysis\n",
    "\n",
    "We can download the summary statistics from LocusZoom. This has been annotated with RSID conveniently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "064c33a8-64dc-4c76-9f31-d85a9e8b1d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation\n",
    "import glob\n",
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "import time\n",
    "import numpy as np\n",
    "import sys\n",
    "from IPython.core.debugger import set_trace # insert 'set_truce()' inside function for debagging\n",
    "import matplotlib as plt\n",
    "\n",
    "# Some job control commands\n",
    "def submitMultiJobs(x, time='3:00:00', mem=2, threads=1, bundle=1, modules=None, store='swarm', node='quick', packing=True, go=False):\n",
    "    \"\"\"\n",
    "    Submit multiple jobs on biowulf\n",
    "    x: LIST of the location of swarmfile\n",
    "    max runtime: quick->4:00:00, norm->48:00:00 be careful when bundle jobs\n",
    "    node: quick or norm\n",
    "    example of modules: modeule='R,plink'\n",
    "    'go=True' will submit the jobs\n",
    "    \"\"\"\n",
    "    swarmdevq=\"swarm -f {F} --time={T} -g {G} -p {PACK} -b {B} -t {THREADS} --logdir {L}{M} --partition={P} --devel\"\n",
    "    a=[]\n",
    "    MODULES=' --module {M}'.format(M=modules)*(modules is not None)\n",
    "    for i in x: \n",
    "        s=swarmdevq.format(F=i, T=time, G=mem, PACK=1+packing, B=bundle, M=MODULES, \n",
    "                           THREADS=threads, L=store, P=node)\n",
    "        if go:\n",
    "            res=subprocess.run(s[:-8].split(\" \"), stdout=subprocess.PIPE)\n",
    "            a.append(res.stdout.decode('utf-8'))\n",
    "        if not go:\n",
    "            res=subprocess.run(s.split(\" \"), stdout=subprocess.PIPE)\n",
    "            t = res.stdout.decode('utf-8').replace(',', '--').replace('\\n', '--').replace(' /spi', '--').split(\"--\")\n",
    "            x = [i for i,x in enumerate(t) if 'cpus-' in x]\n",
    "            print(t[1:3]+t[x[0]:-2])\n",
    "            a='Check!![module, N_jobs, node, mem(x2), and store,bundle] If ok -> go=True!'\n",
    "    return(a)\n",
    "\n",
    "\n",
    "def checkJobStatus(list_of_jobids):\n",
    "    \"\"\"\n",
    "    Get the job status as the list of dataframe with some outputs\n",
    "    \"\"\"\n",
    "    ans = []\n",
    "    index=0\n",
    "    for i in list_of_jobids:\n",
    "        res = subprocess.run(['jobhist', str(i)], stdout=subprocess.PIPE)\n",
    "        res2 = res.stdout.decode().split('\\n')\n",
    "        start = next(i for i,x in enumerate(res2) if 'Jobid' in x)\n",
    "        start_script = next(i for i,x in enumerate(res2) if 'Swarm Command' in x)+2\n",
    "        script = res2[start_script].split('-f')[1]\n",
    "        s = pd.Series(res2[start:])\n",
    "        df = s.str.split(\"\\\\s{2,}\", expand=True)\n",
    "        df = df.rename(columns=df.iloc[0, :])\n",
    "        a=df[1:-1]\n",
    "        print('=========== index=' + str(index) + \": jobID=\" + i + \": \" + script + ' ===============')\n",
    "        print(\"N of Jobs: \" + str(a.shape[0]))\n",
    "        print('N_of not_COMPLETED: '+str(sum(a.State!='COMPLETED')))\n",
    "        print(\"First 5 of longest Runtime job\")\n",
    "        print(a.sort_values('Runtime', ascending=False).head())\n",
    "        print(\"Pending jobs\"+str(list(a[a.State=='PENDING'].Jobid)))\n",
    "        ans.append(a)\n",
    "        index += 1\n",
    "    return (ans)\n",
    "\n",
    "def plotRuntime(Runtime):\n",
    "    \"\"\"\n",
    "    Create plot from Outputted Runtime from checkJobStatus\n",
    "    \"\"\"\n",
    "    def convertH(runtime):\n",
    "        h, m, s = runtime.split(':')\n",
    "        return int(h) + int(m) / 60 + int(s)/3600\n",
    "    Runtime.apply(convertH).plot.hist()\n",
    "\n",
    "def checkSubjob(subjobID):\n",
    "    \"\"\"\n",
    "    Get the command of subjobs to check. \n",
    "    Provide subjobID in string\n",
    "    \"\"\"\n",
    "    header='/spin1/swarm/iwakih2/'\n",
    "    findfolder=header+subjobID.replace(\"_\", '/cmd.')\n",
    "    files = glob.glob(findfolder+'_*')\n",
    "    for file in files:\n",
    "        res = subprocess.run(['cat', file], stdout=subprocess.PIPE)\n",
    "        return(print(res.stdout.decode()))\n",
    "\n",
    "def retrieveTimeouts(x, output):\n",
    "    \"\"\"\n",
    "    Writing timeouted jobs in 'output'\n",
    "    x is the output dataframe from \"checkJobStatus\"\n",
    "    \"\"\"\n",
    "    failed=x[x.State=='TIMEOUT'].Jobid\n",
    "    header='/spin1/swarm/iwakih2/'\n",
    "    findlist=[header+i.replace(\"_\", '/cmd.') for i in failed]\n",
    "    with open(output, 'w') as f:\n",
    "        for i in findlist:\n",
    "            files = glob.glob(i+'_*')\n",
    "            for file in files:\n",
    "                res = subprocess.run(['cat', file], stdout=subprocess.PIPE)\n",
    "                f.write(res.stdout.decode()[3:-2] + '\\n')\n",
    "def cutSwarmByNjobs(swarmfile, N=2000):    \n",
    "    a = []\n",
    "    with open(swarmfile) as f:\n",
    "        lines = f.read().splitlines()\n",
    "        N_split = len(lines)//N\n",
    "        for i in range(N_split+1):\n",
    "            fname,ext = swarmfile.split('.')\n",
    "            newfile='{0}_{1}cut{2}.{3}'.format(fname, str(N), str(i), ext)\n",
    "            a.append(newfile)\n",
    "            with open(newfile, 'w') as f:\n",
    "                f.write('\\n'.join(lines[(i*N):((i+1)*N)]))\n",
    "    return (a)\n",
    "\n",
    "def submitTerminal(command, printing=False, message=''):\n",
    "    # quick command to submit jobs to terminal\n",
    "    start = time.time()\n",
    "    res=subprocess.run(command.split(' '), stdout=subprocess.PIPE)\n",
    "    end = time.time()\n",
    "    sys.stdout.write('EXEC_TIME in sec: '+ str(round(end - start, 3)) + ' : ')\n",
    "    if printing:\n",
    "        print(res.stdout.decode('utf-8'))\n",
    "    if message=='':\n",
    "        return(res.stdout.decode('utf-8'))\n",
    "    else:\n",
    "        print(message, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b739a5ae-ed27-4c0b-a854-bed1bbe87734",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p LocusZoom\n",
    "!mkdir -p LocusCompare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a4f48a-f61e-4e71-a069-de44b9c71d22",
   "metadata": {},
   "source": [
    "## From rsID to gene names\n",
    "\n",
    "Couple of eQTL stats to pull\n",
    "1. eqtlgen site(https://www.eqtlgen.org/)\n",
    "2. Brain-eQTL (https://www.nature.com/articles/s41467-018-04558-1)\n",
    "3. Brain regional eQTL (https://doi.org/10.7303/syn2580853, https://www.synapse.org/#!Synapse:syn17015233)\n",
    "\n",
    "These eqtl files are very large and wouldn't want to load it on python. \n",
    "\n",
    "Reference\n",
    "* 2: Qi, T., Wu, Y., Zeng, J. et al. Identifying gene targets for brain-related traits using transcriptomic and methylomic data from blood. Nat Commun 9, 2282 (2018).\n",
    "* 3: Allen, M et al. Human whole genome genotype and transcriptome data for Alzheimer's and other neurodegenerative diseases. Sci. Data 3:160089 doi: 10.1038/sdata.2016.89 (2016).https://www.nature.com/articles/sdata201689"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2107875f-d5a7-47a1-b784-fc3cc0b696b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "snps=['rs60871478']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d4e1272-1e14-47c8-9f55-354ee9517777",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tissue\n",
    "tissue='brain'\n",
    "\n",
    "# Load the target gwas\n",
    "gwas_path=f'/data/CARD/projects/longGWASnextflow/BiomarkerGWAS-2/METAL/FUMA/log_CSF_pTau.Pi_Deming.tbl.gz'\n",
    "gwas=pd.read_csv(gwas_path, sep='\\t', engine='c')\n",
    "\n",
    "\n",
    "# get list of genes close to snps\n",
    "for snp in snps:\n",
    "    print(snp)\n",
    "    cmd=f'mkdir -p {snp}/{tissue}'\n",
    "    \n",
    "    # brain\n",
    "    cmd = list()\n",
    "    eQTLpath = '/data/CARD/OTHER/cortical_meta_eqtl_summary_stats/Cortex_MetaAnalysis_ROSMAP_CMC_HBCC_Mayo_cis_eQTL_release.csv'\n",
    "    ofile = f'LocusCompare/{snp}/{tissue}/eqtl.txt'\n",
    "    cmd.append(f\"head -n1 {eQTLpath} > {ofile}\")\n",
    "    cmd.append(f\"awk 'BEGIN{{FS=\\\",\\\"}};{{if($3==\\\"{snp}\\\")print}}' {eQTLpath} >> {ofile}\")\n",
    "    cmd = ';'.join(cmd)\n",
    "    !{cmd}\n",
    "    \n",
    "    # Read the output above and standardize the format\n",
    "    d = pd.read_csv(f'LocusCompare/{snp}/{tissue}/eqtl.txt')\n",
    "    d = d.rename(columns={'chromosome':'chr', 'snpLocation':'pos'})\n",
    "    d['tissue'] = tissue\n",
    "    d=d.rename(columns={'A1':'ref', 'A2':'alt', 'A2freq':'altFreq'}) # Flipped.\n",
    "    d=d[['snpid', 'chr', 'pos', 'ref', 'alt', 'altFreq', 'tissue', 'gene', 'geneSymbol',  'expressionIncreasingAllele','pvalue', 'FDR',]].copy()\n",
    "    d.to_csv(f'LocusCompare/{snp}/{tissue}/eqtl_std.csv', index=False)\n",
    "    \n",
    "    # Gene list\n",
    "    genes_interest=d.gene[d.FDR<0.05]\n",
    "    print(gene_interest)\n",
    "    \n",
    "    for gene in genes_interest:\n",
    "        print(gene, 'processing')\n",
    "        # get the eqtl sumstats for the gene\n",
    "        eQTLpath = '/data/CARD/OTHER/cortical_meta_eqtl_summary_stats/Cortex_MetaAnalysis_ROSMAP_CMC_HBCC_Mayo_cis_eQTL_release.csv'\n",
    "        ofile = f'LocusCompare/{snp}/{tissue}/{gene}_eqtl.txt'\n",
    "        cmd.append(f\"echo 'rsid pval'> {ofile}\")\n",
    "        cmd.append(f\"awk 'BEGIN{{FS=\\\",\\\"}};{{if($5==\\\"{gene}\\\")print $3,$8}}' {eQTLpath} >> {ofile}\")\n",
    "        cmd=(';'.join(cmd))\n",
    "        !{cmd}\n",
    "\n",
    "        # Slice the gwas\n",
    "        d=pd.read_csv(f'LocusCompare/{snp}/{tissue}/{gene}_eqtl.txt', sep=' ')\n",
    "        dg=gwas[gwas.rsID.isin(d.rsid)].copy()\n",
    "        dg['rsid']=dg.rsID\n",
    "        dg['pval']=dg['P-value']\n",
    "        dg[['rsid', 'pval']].to_csv(f'LocusCompare/{snp}/{tissue}/{gene}_gwas.txt', sep=' ', index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8e202660-aec0-439e-be2a-fc59fa8e3834",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tissue\n",
    "tissue='blood'\n",
    "\n",
    "# Load the target gwas\n",
    "gwas_path=f'/data/CARD/projects/longGWASnextflow/BiomarkerGWAS-2/METAL/FUMA/log_CSF_pTau.Pi_Deming.tbl.gz'\n",
    "gwas=pd.read_csv(gwas_path, sep='\\t', engine='c')\n",
    "gwas=gwas[(gwas.OBS_CT_TOTAL>3000)&(gwas.HetISq<80)].copy()\n",
    "\n",
    "# get list of genes close to snps\n",
    "for snp in snps:\n",
    "    print(snp)\n",
    "    cmd=f'mkdir -p {snp}/{tissue}'\n",
    "    !{cmd}\n",
    "    \n",
    "    # blood\n",
    "    cmd = list()\n",
    "    eQTLpath = '/data/CARD/OTHER/eqtlgen_summary_stats/2019-12-11-cis-eQTLsFDR-ProbeLevel-CohortInfoRemoved-BonferroniAdded.txt.gz'\n",
    "    ofile = f'LocusCompare/{snp}_blood_eqtl.txt'\n",
    "    cmd.append(f\"zcat {eQTLpath} | head -n1 > {ofile}\")\n",
    "    cmd.append(f\"zcat {eQTLpath} | awk '{{if($2==\\\"{snp}\\\")print}}' >> {ofile}\")\n",
    "    cmd = ';'.join(cmd)\n",
    "#     !{cmd}\n",
    "    \n",
    "    # Read the output above and standardize the format\n",
    "    d = pd.read_csv(f'LocusCompare/{snp}/{tissue}/eqtl.txt', sep='\\t')\n",
    "    d = d.rename(columns={'chromosome':'chr', 'snpLocation':'pos'})\n",
    "    d['tissue'] = tissue\n",
    "    d['expressionIncreasingAllele'] = d.AssessedAllele.where(d.Zscore>0, d.OtherAllele)\n",
    "    d=d.rename(columns={'AssessedAllele':'ref', 'OtherAllele':'alt', \n",
    "                        'SNP':'snpid', 'SNPChr':'chr', 'SNPPos':'pos', \n",
    "                        'Pvalue':'pvalue', 'Gene':'gene', 'GeneSymbol':'geneSymbol'}) # Flipped.\n",
    "    d['altFreq']=np.nan\n",
    "    d=d[['snpid', 'chr', 'pos', 'ref', 'alt', 'altFreq', 'tissue', 'gene', 'geneSymbol',  'expressionIncreasingAllele','pvalue', 'FDR',]].copy()\n",
    "    d.to_csv(f'LocusCompare/{snp}/{tissue}/eqtl_std.csv', index=False)\n",
    "    \n",
    "    # Gene list\n",
    "    genes_interest=d.gene[d.FDR<0.05]\n",
    "    print(gene_interest)\n",
    "    \n",
    "    for gene in genes:\n",
    "        print(gene, 'processing')\n",
    "        # get the eqtl sumstats for the gene\n",
    "        cmd = list()\n",
    "        eQTLpath = '/data/CARD/OTHER/eqtlgen_summary_stats/2019-12-11-cis-eQTLsFDR-ProbeLevel-CohortInfoRemoved-BonferroniAdded.txt.gz'\n",
    "        ofile = f'LocusCompare/eQTL/{gene}_blood_eqtl.txt'\n",
    "        cmd.append(f\"echo 'rsid pval'> {ofile}\")\n",
    "        cmd.append(f\"zcat {eQTLpath} | awk '{{if($8==\\\"{gene}\\\")print $2,$1}}' >> {ofile}\")\n",
    "        cmd=';'.join(cmd)\n",
    "        !{cmd}\n",
    "\n",
    "        # Slice the gwas\n",
    "        d=pd.read_csv(f'LocusCompare/{snp}/{tissue}/{gene}_eqtl.txt', sep=' ')\n",
    "        dg=gwas[gwas.rsID.isin(d.rsid)].copy()\n",
    "        dg['rsid']=dg.rsID\n",
    "        dg['pval']=dg['P-value']\n",
    "        dg[['rsid', 'pval']].to_csv(f'LocusCompare/{snp}/{tissue}/{gene}_gwas.txt', sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790b5a74-1cf5-4c6c-af74-fd1444206a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENSG00000240230_eqtl X\n",
    "ENSG00000239857_eqtl X\n",
    "ENSG00000188191_eqtl ?\n",
    "ENSG00000164849_eqtl X\n",
    "ENSG00000164818_eqtl O\n",
    "ENSG00000146540_eqtl X\n",
    "ENSG00000105963_eqtl X\n",
    "\n",
    "# LocusCompare browser is useful to check for a smaller number of comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39be3bce-9609-4e6a-a50a-f0b2a8093012",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python/3.9",
   "language": "python",
   "name": "py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
